{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "from langchain.text_splitter import Language\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sohamkhopkar/Desktop/LangChain Projects/Final-major/Github'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir test_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"test_repo/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<git.repo.base.Repo '/Users/sohamkhopkar/Desktop/LangChain Projects/Final-major/Github/test_repo/.git'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Repo.clone_from(\"https://github.com/Sohamm31/Final-major\", to_path=repo_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = GenericLoader.from_filesystem(\"/Users/sohamkhopkar/Desktop/LangChain Projects/Final-major/Github/test_repo\",\n",
    "                                        glob = \"**/*\",\n",
    "                                       suffixes=[\".py\"],\n",
    "                                       parser = LanguageParser(language=Language.PYTHON, parser_threshold=500)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"test_repo/\"\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/Users/sohamkhopkar/Desktop/LangChain Projects/Final-major/Github/test_repo/mock_interview.py', 'language': <Language.PYTHON: 'python'>}, page_content='from langchain_core.prompts import PromptTemplate\\nfrom langchain.chat_models import ChatOpenAI\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_community.document_loaders import PyPDFLoader\\nfrom langchain.output_parsers import StructuredOutputParser,ResponseSchema\\nimport speech_recognition as sr\\nimport threading\\nimport pyttsx3\\nimport time\\nimport os\\nfrom dotenv import load_dotenv\\nload_dotenv() \\n\\napi_key = os.getenv(\\'OPENROUTESERVICE_API_KEY\\')\\nrecognizer = sr.Recognizer()\\ntts = pyttsx3.init()\\n\\ntts.setProperty(\\'rate\\', 180)  \\nvoices = tts.getProperty(\\'voices\\')\\ntts.setProperty(\\'volume\\', 1.0)\\ntts.setProperty(\\'voice\\', voices[117].id)  \\n\\n\\nloader = PyPDFLoader(\"Final-major/Soham Resume TnP Updated May.pdf\")\\npdf = loader.load()\\nall_content = [doc.page_content for doc in pdf]\\n\\nschema = [\\n    ResponseSchema(name=\"question-1\",description=\"Question-1 on resume\"),\\n    ResponseSchema(name=\"question-2\",description=\"Question-2 on resume\"),\\n    ResponseSchema(name=\"question-3\",description=\"Question-3 on resume\"),\\n    ResponseSchema(name=\"question-4\",description=\"Question-4 on resume\"),\\n    ResponseSchema(name=\"question-5\",description=\"Question-5 on resume\")\\n]\\nintro_schema = [\\n    ResponseSchema(name=\"question-1\",description=\"Question-1 on Introduction\"),\\n    ResponseSchema(name=\"question-2\",description=\"Question-2 on Introduction\"),\\n]\\nfeedback_schema = [\\n    ResponseSchema(name=\"Suggestion-1\",description=\"Suggestion-1 on interview\"),\\n    ResponseSchema(name=\"Suggestion-2\",description=\"Suggestion-2 on interview\"),\\n    ResponseSchema(name=\"Suggestion-3\",description=\"Suggestion-3 on interview\"),\\n    ResponseSchema(name=\"Suggestion-4\",description=\"Suggestion-4 on interview\"),\\n    ResponseSchema(name=\"Suggestion-5\",description=\"Suggestion-5 on interview\")\\n]\\nintroduction_parser = StructuredOutputParser.from_response_schemas(intro_schema)\\n\\nparser = StructuredOutputParser.from_response_schemas(schema)\\n\\nfeedback_parser =  StructuredOutputParser.from_response_schemas(feedback_schema)\\n\\ncategorized_feedback_schema = [\\n    ResponseSchema(name=\"Communication\", description=\"Rate the candidate\\'s communication skills on a scale of 1 to 5.\"),\\n    ResponseSchema(name=\"Confidence\", description=\"Rate the candidate\\'s confidence and body language on a scale of 1 to 5.\"),\\n    ResponseSchema(name=\"Technical\", description=\"Rate the candidate\\'s technical knowledge and responses on a scale of 1 to 5.\"),\\n    ResponseSchema(name=\"Resume Fit\", description=\"Rate how well the candidate fits the resume on a scale of 1 to 5.\"),\\n    ResponseSchema(name=\"Improvement Areas\", description=\"Rate the candidate\\'s overall areas for improvement on a scale of 1 to 5.\")\\n]\\ncategorized_feedback_parser = StructuredOutputParser.from_response_schemas(categorized_feedback_schema)\\n\\n# prompt = PromptTemplate(\\n#     template= \"Attached here is a resume.Based on resume frame 5 interview questions.Only questions are to be formed without answers in a proper format.{Resume}\",\\n#     input_variables=[\"Resume\"]\\n# )\\n\\nprompt = PromptTemplate(\\n    template=\"Give 5 interview questions based on the attached resume following is the attached resume./n{Resume}/n{format_instruction}\",\\n    input_variables=[\"Resume\"],\\n    partial_variables={\"format_instruction\":parser.get_format_instructions()}\\n)\\nintro_prompt = PromptTemplate(\\n    template=\"Based on the Introduction form 2 questions for the interview./n{introduction}/n{format_instruction}\",\\n    input_variables=[\"introduction\"],\\n    partial_variables={\"format_instruction\": introduction_parser.get_format_instructions()}\\n)\\nfeedback_prompt = PromptTemplate(\\n    template=\"You are an HR assistant. Based on the following interview responses, provide personalized feedback in 5 points./n{interview_summary}/n{format_instruction}\",\\n    input_variables=[\"interview_summary\"],\\n    partial_variables={\"format_instruction\": feedback_parser.get_format_instructions()}\\n)\\ncategorized_feedback_prompt = PromptTemplate(\\n    template=\"You are an HR assistant. Based on the following interview responses, provide categorized feedback in the following sections: Communication, Confidence, Technical, Resume Fit, Improvement Areas.\\\\n{interview_summary}\\\\n{format_instruction}\",\\n    input_variables=[\"interview_summary\"],\\n    partial_variables={\"format_instruction\": categorized_feedback_parser.get_format_instructions()}\\n)\\n\\n\\n\\nllm = ChatOpenAI(\\n    model_name=\"deepseek/deepseek-r1-0528-qwen3-8b:free\",  \\n    openai_api_key=api_key,\\n    openai_api_base=\"https://openrouter.ai/api/v1\", \\n)\\n\\n\\n\\nchain  = prompt | llm | parser\\nquestions = chain.invoke({\"Resume\":all_content})\\nresponses = {}\\n\\ndef speak(text, pause=2):\\n    tts.say(text)\\n    tts.runAndWait()\\n    time.sleep(pause)\\n\\ndef listen():\\n    print(\"Listening... Press Enter when you\\'re done speaking.\")\\n    audio_data = sr.AudioData(b\\'\\', 16000, 2)\\n    with sr.Microphone() as source:\\n        recognizer.adjust_for_ambient_noise(source)\\n        collected_audio = []\\n        stop_listening = False\\n        while not stop_listening:\\n            try:\\n                audio_chunk = recognizer.listen(source, timeout=1, phrase_time_limit=3)\\n                collected_audio.append(audio_chunk)\\n            except sr.WaitTimeoutError:\\n                continue\\n            if input() == \\'\\':\\n                stop_listening = True\\n\\n        print(\"Transcribing...\")\\n        try:\\n            full_audio = sr.AudioData(b\\'\\'.join(chunk.get_raw_data() for chunk in collected_audio),\\n                                      collected_audio[0].sample_rate,\\n                                      collected_audio[0].sample_width)\\n            return recognizer.recognize_google(full_audio)\\n        except Exception as e:\\n            return f\"Error in transcription: {e}\"\\n\\ndef generate_summary(responses_dict, questions_dict):\\n    summary_lines = []\\n    for key in questions_dict:\\n        question = questions_dict[key]\\n        answer = responses_dict.get(key, \"No response.\")\\n        summary_lines.append(f\"Q: {question}\\\\nA: {answer}\\\\n\")\\n    return \"\\\\n\".join(summary_lines)\\n\\nspeak(\"Introduce Yourself Please\")\\nintroduction = listen()\\n\\nintroduction_chain = intro_prompt | llm | introduction_parser\\nintro_questions = introduction_chain.invoke({\"introduction\":introduction})\\n\\nfor key, question in intro_questions.items():\\n    print(f\"\\\\nQuestion: {question}\")\\n    speak(question, pause=3)\\n\\n    print(\"Your response:\")\\n    intro_answer = listen()\\n    print(f\"You said: {intro_answer}\")\\n    responses[key] = intro_answer\\n\\n\\n\\nfor key, question in questions.items():\\n    print(f\"\\\\nQuestion: {question}\")\\n    speak(question, pause=3)\\n\\n    print(\"Your response:\")\\n    answer = listen()\\n    print(f\"You said: {answer}\")\\n    responses[key] = answer\\n\\nsummary_text = generate_summary(responses, questions)\\nprint(\"\\\\nInterview Summary:\\\\n\")\\nprint(summary_text)\\nprint(\"\\\\nInterview Summary:\\\\n\")\\nprint(summary_text)\\n\\n\\n\\nsummary_chain = feedback_prompt | llm | feedback_parser\\n\\ninterview_review = summary_chain.invoke({\"interview_summary\":summary_text})\\n\\n\\n\\n\\ncategorized_feedback_chain = categorized_feedback_prompt | llm | categorized_feedback_parser\\ncategorized_feedback = categorized_feedback_chain.invoke({\"interview_summary\": summary_text})\\n\\nspeak(str(interview_review))\\n\\nprint(\"\\\\nCategorized Feedback:\\\\n\")\\nfor category, feedback in categorized_feedback.items():\\n    print(f\"{category}: {feedback}\\\\n\")\\n')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_splitter = RecursiveCharacterTextSplitter.from_language(language = Language.PYTHON,\n",
    "                                                             chunk_size = 2000,\n",
    "                                                             chunk_overlap = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = documents_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('OPENROUTESERVICE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vr/k31rtn_168v7kvg7k8xq_v540000gn/T/ipykernel_54075/4043855499.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(texts, embedding=embeddings, persist_directory='./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vr/k31rtn_168v7kvg7k8xq_v540000gn/T/ipykernel_54075/1246081259.py:1: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "vectordb.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"deepseek/deepseek-r1-0528-qwen3-8b:free\",  # You can use any OpenRouter-supported model\n",
    "    openai_api_key=api_key,\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",  # Important for OpenRouter!\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(llm=llm, memory_key = \"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\":3}), memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Summarise the entire project with its key functionalities\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can see you're interested in understanding the entire structure and functionality of the project, which appears to be an interactive interview simulation system.\n",
      "\n",
      "This seems to be an interview practice system that:\n",
      "1. Takes a resume (loaded from PDF)\n",
      "2. Generates interview questions based on the resume content\n",
      "3. Conducts a voice-based interview using speech recognition and text-to-speech\n",
      "4. Collects and organizes interview responses\n",
      "5. Generates structured feedback categorized by different assessment areas\n",
      "\n",
      "The key functionalities include:\n",
      "- Resume parsing and question generation\n",
      "- Voice-based interview process using speech recognition and synthesis\n",
      "- Structured response collection\n",
      "- Automated interview summary generation\n",
      "- Categorized feedback generation\n",
      "- Structured output parsing\n",
      "\n",
      "This type of system could be useful for interview preparation, job candidate assessment, or educational purposes where verbal responses need to be captured and evaluated.\n"
     ]
    }
   ],
   "source": [
    "result = qa(question)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
